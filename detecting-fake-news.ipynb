{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":310019,"sourceType":"datasetVersion","datasetId":129603}],"dockerImageVersionId":30096,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Make necessary imports ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T06:17:37.389287Z","iopub.execute_input":"2021-07-05T06:17:37.38975Z","iopub.status.idle":"2021-07-05T06:17:38.662257Z","shell.execute_reply.started":"2021-07-05T06:17:37.389667Z","shell.execute_reply":"2021-07-05T06:17:38.661172Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Now, let’s read the data into a DataFrame, and get the shape of the data and the first 5 records.","metadata":{}},{"cell_type":"code","source":"#Read the data\ndf=pd.read_csv('../input/textdb3/fake_or_real_news.csv')\n\n#Get shape and head\ndf.shape\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:17:38.664564Z","iopub.execute_input":"2021-07-05T06:17:38.665038Z","iopub.status.idle":"2021-07-05T06:17:39.625359Z","shell.execute_reply.started":"2021-07-05T06:17:38.664973Z","shell.execute_reply":"2021-07-05T06:17:39.624266Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## And get the labels from the DataFrame","metadata":{}},{"cell_type":"code","source":"#DataFlair - Get the labels\nlabels=df.label\nlabels.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:17:39.626968Z","iopub.execute_input":"2021-07-05T06:17:39.62734Z","iopub.status.idle":"2021-07-05T06:17:39.63704Z","shell.execute_reply.started":"2021-07-05T06:17:39.627298Z","shell.execute_reply":"2021-07-05T06:17:39.635857Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Split the dataset into training and testing sets.","metadata":{}},{"cell_type":"code","source":"#DataFlair - Split the dataset\nx_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:17:39.638604Z","iopub.execute_input":"2021-07-05T06:17:39.638941Z","iopub.status.idle":"2021-07-05T06:17:39.658364Z","shell.execute_reply.started":"2021-07-05T06:17:39.638898Z","shell.execute_reply":"2021-07-05T06:17:39.656601Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Now, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set.","metadata":{}},{"cell_type":"code","source":"##DataFlair - Initialize a TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df =0.9)\n## DataFlair - fit and transform train set, transform test set\ntfidf_train = tfidf_vectorizer.fit_transform(x_train)\ntfidf_test = tfidf_vectorizer.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:17:39.661769Z","iopub.execute_input":"2021-07-05T06:17:39.662363Z","iopub.status.idle":"2021-07-05T06:17:44.929788Z","shell.execute_reply.started":"2021-07-05T06:17:39.662308Z","shell.execute_reply":"2021-07-05T06:17:44.928918Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Then, we’ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics.","metadata":{}},{"cell_type":"code","source":"#DataFlair - Initialize a PassiveAggressiveClassifier\npac=PassiveAggressiveClassifier(max_iter=50)\npac.fit(tfidf_train,y_train)\n\n#DataFlair - Predict on the test set and calculate accuracy\ny_pred=pac.predict(tfidf_test)\nscore=accuracy_score(y_test,y_pred)\nprint(f'Accuracy: {round(score*100,2)}%')","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:17:44.930891Z","iopub.execute_input":"2021-07-05T06:17:44.931348Z","iopub.status.idle":"2021-07-05T06:17:45.082723Z","shell.execute_reply.started":"2021-07-05T06:17:44.931316Z","shell.execute_reply":"2021-07-05T06:17:45.081842Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We got an accuracy of 92.82% with this model. Finally, let’s print out a confusion matrix to gain insight into the number of false and true negatives and positives.","metadata":{}},{"cell_type":"code","source":"#DataFlair - Build confusion matrix\nconfusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:17:45.083709Z","iopub.execute_input":"2021-07-05T06:17:45.084109Z","iopub.status.idle":"2021-07-05T06:17:45.096613Z","shell.execute_reply.started":"2021-07-05T06:17:45.084079Z","shell.execute_reply":"2021-07-05T06:17:45.095545Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Summary\n\nToday, we learned to detect fake news with Python. We took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit our model. We ended up obtaining an accuracy of 92.82% in magnitude.\n\nHope you enjoyed the fake news detection python project. Keep visiting DataFlair for more interesting python, data science, and machine learning projects.","metadata":{}},{"cell_type":"markdown","source":"Thanks to DataFlair I learn a lot from it.","metadata":{}}]}